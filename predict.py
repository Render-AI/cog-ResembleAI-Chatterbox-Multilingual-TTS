import os
import random
import tempfile
import requests
import gc
import torch.cuda

from typing import Optional
import numpy as np
import torch
import scipy.io.wavfile as wavfile
from cog import BasePredictor, Input, Path

# Fixed import path from app.py
from chatterbox.mtl_tts import ChatterboxMultilingualTTS
# Optimized Chatterbox Multilingual TTS for Replicate Cog
# - GPU memory optimizations for A100 and lower-end cards
# - Efficient audio prompt downloading with streaming
# - Memory cleanup after generation
# - TF32 enabled for better performance on modern GPUs


# Language configuration copied from app.py
LANGUAGE_CONFIG = {
    "ar": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/ar_m1.flac",
        "text": "ÙÙŠ Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ù…Ø§Ø¶ÙŠØŒ ÙˆØµÙ„Ù†Ø§ Ø¥Ù„Ù‰ Ù…Ø¹Ù„Ù… Ø¬Ø¯ÙŠØ¯ Ø¨Ù…Ù„ÙŠØ§Ø±ÙŠÙ† Ù…Ù† Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø§Øª Ø¹Ù„Ù‰ Ù‚Ù†Ø§ØªÙ†Ø§ Ø¹Ù„Ù‰ ÙŠÙˆØªÙŠÙˆØ¨."
    },
    "da": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/da_m1.flac",
        "text": "Sidste mÃ¥ned nÃ¥ede vi en ny milepÃ¦l med to milliarder visninger pÃ¥ vores YouTube-kanal."
    },
    "de": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/de_f1.flac",
        "text": "Letzten Monat haben wir einen neuen Meilenstein erreicht: zwei Milliarden Aufrufe auf unserem YouTube-Kanal."
    },
    "el": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/el_m.flac",
        "text": "Î¤Î¿Î½ Ï€ÎµÏÎ±ÏƒÎ¼Î­Î½Î¿ Î¼Î®Î½Î±, Ï†Ï„Î¬ÏƒÎ±Î¼Îµ ÏƒÎµ Î­Î½Î± Î½Î­Î¿ Î¿ÏÏŒÏƒÎ·Î¼Î¿ Î¼Îµ Î´ÏÎ¿ Î´Î¹ÏƒÎµÎºÎ±Ï„Î¿Î¼Î¼ÏÏÎ¹Î± Ï€ÏÎ¿Î²Î¿Î»Î­Ï‚ ÏƒÏ„Î¿ ÎºÎ±Î½Î¬Î»Î¹ Î¼Î±Ï‚ ÏƒÏ„Î¿ YouTube."
    },
    "en": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/en_f1.flac",
        "text": "Last month, we reached a new milestone with two billion views on our YouTube channel."
    },
    "es": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/es_f1.flac",
        "text": "El mes pasado alcanzamos un nuevo hito: dos mil millones de visualizaciones en nuestro canal de YouTube."
    },
    "fi": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/fi_m.flac",
        "text": "Viime kuussa saavutimme uuden virstanpylvÃ¤Ã¤n kahden miljardin katselukerran kanssa YouTube-kanavallamme."
    },
    "fr": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/fr_f1.flac",
        "text": "Le mois dernier, nous avons atteint un nouveau jalon avec deux milliards de vues sur notre chaÃ®ne YouTube."
    },
    "he": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/he_m1.flac",
        "text": "×‘×—×•×“×© ×©×¢×‘×¨ ×”×’×¢× ×• ×œ××‘×Ÿ ×“×¨×š ×—×“×©×” ×¢× ×©× ×™ ×ž×™×œ×™××¨×“ ×¦×¤×™×•×ª ×‘×¢×¨×•×¥ ×”×™×•×˜×™×•×‘ ×©×œ× ×•."
    },
    "hi": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/hi_f1.flac",
        "text": "à¤ªà¤¿à¤›à¤²à¥‡ à¤®à¤¹à¥€à¤¨à¥‡ à¤¹à¤®à¤¨à¥‡ à¤à¤• à¤¨à¤¯à¤¾ à¤®à¥€à¤² à¤•à¤¾ à¤ªà¤¤à¥à¤¥à¤° à¤›à¥à¤†: à¤¹à¤®à¤¾à¤°à¥‡ YouTube à¤šà¥ˆà¤¨à¤² à¤ªà¤° à¤¦à¥‹ à¤…à¤°à¤¬ à¤µà¥à¤¯à¥‚à¤œà¤¼à¥¤"
    },
    "it": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/it_m1.flac",
        "text": "Il mese scorso abbiamo raggiunto un nuovo traguardo: due miliardi di visualizzazioni sul nostro canale YouTube."
    },
    "ja": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/ja_f.flac",
        "text": "å…ˆæœˆã€ç§ãŸã¡ã®YouTubeãƒãƒ£ãƒ³ãƒãƒ«ã§äºŒåå„„å›žã®å†ç”Ÿå›žæ•°ã¨ã„ã†æ–°ãŸãªãƒžã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã«åˆ°é”ã—ã¾ã—ãŸã€‚"
    },
    "ko": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/ko_f.flac",
        "text": "ì§€ë‚œë‹¬ ìš°ë¦¬ëŠ” ìœ íŠœë¸Œ ì±„ë„ì—ì„œ ì´ì‹­ì–µ ì¡°íšŒìˆ˜ë¼ëŠ” ìƒˆë¡œìš´ ì´ì •í‘œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤."
    },
    "ms": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/ms_f.flac",
        "text": "Bulan lepas, kami mencapai pencapaian baru dengan dua bilion tontonan di saluran YouTube kami."
    },
    "nl": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/nl_m.flac",
        "text": "Vorige maand bereikten we een nieuwe mijlpaal met twee miljard weergaven op ons YouTube-kanaal."
    },
    "no": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/no_f1.flac",
        "text": "Forrige mÃ¥ned nÃ¥dde vi en ny milepÃ¦l med to milliarder visninger pÃ¥ YouTube-kanalen vÃ¥r."
    },
    "pl": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/pl_m.flac",
        "text": "W zeszÅ‚ym miesiÄ…cu osiÄ…gnÄ™liÅ›my nowy kamieÅ„ milowy z dwoma miliardami wyÅ›wietleÅ„ na naszym kanale YouTube."
    },
    "pt": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/pt_m1.flac",
        "text": "No mÃªs passado, alcanÃ§Ã¡mos um novo marco: dois mil milhÃµes de visualizaÃ§Ãµes no nosso canal do YouTube."
    },
    "ru": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/ru_m.flac",
        "text": "Ð’ Ð¿Ñ€Ð¾ÑˆÐ»Ð¾Ð¼ Ð¼ÐµÑÑÑ†Ðµ Ð¼Ñ‹ Ð´Ð¾ÑÑ‚Ð¸Ð³Ð»Ð¸ Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ñ€ÑƒÐ±ÐµÐ¶Ð°: Ð´Ð²Ð° Ð¼Ð¸Ð»Ð»Ð¸Ð°Ñ€Ð´Ð° Ð¿Ñ€Ð¾ÑÐ¼Ð¾Ñ‚Ñ€Ð¾Ð² Ð½Ð° Ð½Ð°ÑˆÐµÐ¼ YouTube-ÐºÐ°Ð½Ð°Ð»Ðµ."
    },
    "sv": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/sv_f.flac",
        "text": "FÃ¶rra mÃ¥naden nÃ¥dde vi en ny milstolpe med tvÃ¥ miljarder visningar pÃ¥ vÃ¥r YouTube-kanal."
    },
    "sw": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/sw_m.flac",
        "text": "Mwezi uliopita, tulifika hatua mpya ya maoni ya bilioni mbili kweny kituo chetu cha YouTube."
    },
    "tr": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/tr_m.flac",
        "text": "GeÃ§en ay YouTube kanalÄ±mÄ±zda iki milyar gÃ¶rÃ¼ntÃ¼leme ile yeni bir dÃ¶nÃ¼m noktasÄ±na ulaÅŸtÄ±k."
    },
    "zh": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/zh_f.flac",
        "text": "ä¸Šä¸ªæœˆï¼Œæˆ‘ä»¬è¾¾åˆ°äº†ä¸€ä¸ªæ–°çš„é‡Œç¨‹ç¢‘ï¼Œæˆ‘ä»¬çš„YouTubeé¢‘é“è§‚çœ‹æ¬¡æ•°è¾¾åˆ°äº†äºŒåäº¿æ¬¡ï¼Œè¿™ç»å¯¹ä»¤äººéš¾ä»¥ç½®ä¿¡ã€‚"
    },
}


class Predictor(BasePredictor):
    def setup(self) -> None:
        """Load the model - adapted from app.py get_or_load_model()"""
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ðŸš€ Running on device: {self.device}")
        
        try:
            self.model = ChatterboxMultilingualTTS.from_pretrained(self.device)
            if hasattr(self.model, 'to') and str(self.model.device) != self.device:
                self.model.to(self.device)
            print(f"Model loaded successfully. Device: {getattr(self.model, 'device', 'N/A')}")
        except Exception as e:
            print(f"Error loading model: {e}")
            raise

        # Memory optimization for better GPU utilization
        if self.device == "cuda":
            torch.cuda.empty_cache()
            # Enable memory efficient attention
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True
            # Enable optimized memory format
            torch.backends.cudnn.benchmark = True

    def set_seed(self, seed: int):
        """Set random seed - copied from app.py"""
        torch.manual_seed(seed)
        if self.device == "cuda":
            torch.cuda.manual_seed(seed)
            torch.cuda.manual_seed_all(seed)
        random.seed(seed)

    def default_audio_for_ui(self, lang: str) -> str:
        """Get default audio prompt for language - with URL download support"""
        url = LANGUAGE_CONFIG.get(lang, {}).get("audio")
        if url and url.startswith('http'):
            # Download the URL to a temporary file
            try:
                print(f"Downloading audio prompt from {url}")
                response = requests.get(url, timeout=30, stream=True)
                response.raise_for_status()
                temp_path = tempfile.mktemp(suffix=".flac")
                with open(temp_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
                return temp_path
            except Exception as e:
                print(f"Warning: Failed to download audio prompt from {url}: {e}")
                print("Continuing without reference audio...")
                return None
        return url

    def predict(
        self,
        text_to_synthesize: str = Input(description="Text to synthesize into speech (max 300 chars)"),
        language_id: str = Input(
            description="Language code",
            choices=list(LANGUAGE_CONFIG.keys()),
            default="en"
        ),
        reference_audio: Optional[Path] = Input(
            description="Optional reference audio file for voice style",
            default=None
        ),
        exaggeration: float = Input(
            description="Speech expressiveness (0.25-2.0)",
            ge=0.25,
            le=2.0,
            default=0.5
        ),
        temperature: float = Input(
            description="Generation randomness (0.05-5.0)",
            ge=0.05,
            le=5.0,
            default=0.8
        ),
        seed: int = Input(
            description="Random seed (0 for random)",
            ge=0,
            default=0
        ),
        cfg_weight: float = Input(
            description="CFG weight (0.0-1.0)",
            ge=0.0,
            le=1.0,
            default=0.5
        )
    ) -> Path:
        """Generate TTS audio - logic copied from app.py generate_tts_audio()"""
        
        if not self.model:
            raise RuntimeError("TTS model is not loaded.")

        # Set seed if provided
        if seed != 0:
            self.set_seed(seed)

        print(f"Generating audio for text: '{text_to_synthesize[:50]}...'")
        
        # Handle optional audio prompt - logic from app.py
        if reference_audio:
            chosen_prompt = str(reference_audio)
        else:
            chosen_prompt = self.default_audio_for_ui(language_id)

        # Prepare generation kwargs - copied from app.py
        generate_kwargs = {
            "exaggeration": exaggeration,
            "temperature": temperature,
            "cfg_weight": cfg_weight,
        }
        
        if chosen_prompt:
            generate_kwargs["audio_prompt_path"] = chosen_prompt
            print(f"Using audio prompt: {chosen_prompt}")
        else:
            print("No audio prompt provided; using default voice.")

        try:
            # Core generation call - exactly from app.py
            wav = self.model.generate(
                text_to_synthesize[:300],  # Truncate text to max chars
                language_id=language_id,
                **generate_kwargs
            )
            print("Audio generation complete.")
            
            # Convert to numpy and get sample rate - from app.py
            sample_rate = self.model.sr
            audio_array = wav.squeeze(0).numpy()
            
            # Save to temporary file for Cog to serve
            output_path = Path(tempfile.mktemp(suffix=".wav"))
            wavfile.write(str(output_path), sample_rate, audio_array)
            print(f"Audio saved to: {output_path}")
            
            
            # Memory cleanup for better performance
            if self.device == "cuda":
                torch.cuda.empty_cache()
                gc.collect()
            
            return output_path
            
        except Exception as e:
            print(f"Error during audio generation: {e}")
            raise
